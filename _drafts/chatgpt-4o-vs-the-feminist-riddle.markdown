---
layout: post
title:  "ChatGPT 4o vs. The Feminist Riddle"
date:   2022-02-15 13:24:40 -0700
categories:
---

## I.

Before we discuss *artificial* intelligence, let&rsquo;s discuss normal intelligence. Consider the sequence 1, 4, 9, 16. What number comes next? The answer is 3. The sequence is governed by the equation:

$$f(x) = \frac{229}{30}x^5 - \frac{1385}{12}x^4 + 658x^3 - \frac{20983}{12}x^2 + \frac{64121}{30}x - 938 $$

I suspect that you feel that answer is somehow underhanded. You may protest that it is not &ldquo;parsimonious&rdquo;. What do we mean by these things?

The real world is governed by patterns. No two apples are exactly alike but any two are overwhelmingly similar. Feathers and fuzz fall slowly while anvils and cannonballs fall quickly. Most plants have the fundamental needs of fertile soil, water, and sunlight. Even plants with very dissimilar needs may show similar symptomatology when things go wrong&mdash;sun-shy forest floor plants and sun-hardened desert plants may both pale and whither if the balance of sun is off.

Intelligence is the capacity to notice patterns, work out the rules that govern them, and apply those rules to generate actionable predictions. Where observations underdetermine a pattern's governing rule, an intelligent person recruits a metapattern: among possible rules, the one which has appeared most frequently in the past is the most likely to appear again. Questions like &ldquo;consider the sequence 1, 4, 9, 16: what number comes next?&rdquo; thus assess intelligence because rules like $$f(x) = x^2$$ *more commonly govern* the everyday experiences of a normal person than higher-order, excessively non-monotonic polynomials.

In the case of math, there are literally infinite rules that can generate the sequence $$[1, 4, 9, 16]$$. To be paralyzed by the choices and refuse to answer the question is not intelligence but sophistry&mdash;*intelligence generates actionable predictions*.

## II.

Imagine a parrot trained since hatching to say "forty-four". You ask it "What's four times eleven?" When it squawks "forty-four! forty-four!" at you, is it correct?

Parrots certainly show cognitive abilities beyond those of many other animals. But nobody seriously claims that the average



A riddle from the 1970s sought to put a spotlight gender stereotypes:

> A father and his son are in a car accident. The father dies on the spot. The son is rushed to the ER. The attending surgeon looks at the boy and says, &ldquo;I can not operate on this boy. He's my son!&rdquo; How can this be?

The intended answer, of course, is that the surgeon is his mother&mdash;a possibility which some 80% of Americans reportedly fail to consider[^surgeon-assumption-study].

[^surgeon-assumption-study]: Kirsten N. Morehouse, Benedek Kurdi, Ece Hakim, Mahzarin R. Banaji. When a stereotype dumbfounds: Probing the nature of the surgeon = male belief, Current Research in Ecological and Social Psychology, Volume 3, 2022, 100044, ISSN 2666-6227, https://doi.org/10.1016/j.cresp.2022.100044.  (https://www.sciencedirect.com/science/article/pii/S2666622722000119)

Twitter has been putting the question to the recently-released ChatGPT 4o, but with a twist: swapping the roles of the mother and father so that they align with the prevailing stereotype.

<div style="align: center;"> <blockquote class="twitter-tweet"><p lang="en" dir="ltr">This is not funny anymore. <a href="https://t.co/PoHhErT8zZ">pic.twitter.com/PoHhErT8zZ</a></p>&mdash; Santiago (@svpino) <a href="https://twitter.com/svpino/status/1791156005331665085?ref_src=twsrc%5Etfw">May 16, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>


Do you feel a little bit cheated by that answer? Do you want to protest that 25 seems more &ldquo;parsimonious&rdquo;?

The things we experience in daily life are more often governed by simple rather than complex polynomials. More often things like $$x^2$$


Worse still is the person who becomes paralyzed by the realization that the problem is underspecified


ChatGPT is alleged to be akin to a human mind, or something approaching it (or, occasionally, something surpassing it). Thus the claim that ChatGPT is "correct" implies a kind of correctness deeper than a parrot "correctly" screeching the only number it knows in response to an arithmetic problem contrived to demand that specific response. It implies something more than *contrived correctness*, or *coincidental correctness*. It implies a *correct process* which can reliably generate other correct answers.
Correct answers are the result of correct processes.


> A woman 


The people who insist that ChatGPT is correct thus imply its thought process. We can test this: we can simply *ask* ChatGPT whether it believes the driver and the doctor are the same person.

That's right, I paid $21.55 just to argue internet sophists. I forever renounce any claim to stoicism.



> A woman drives her son to the hospital. The doctor exclaims: "I can't operate on this boy!"

Any mentally competent speaker of English understands the woman and the doctor to be different people.

- A woman drives her son to the hospital. She exclaims: "I can't operate on this boy!"
- A woman drives her son to the hospital and exclaims: "I can't operate on this boy!"


Man bites dog (inversion of subject object ordering is allowed in some circumstances (need to find example) but )



what becomes very clear as you probe ChatGPT 4o is that it has nothing resembling the thought process or model of the agents in the riddle as its defenders allege.


> The dog brought a ball back from the park. It must be one that somebody lost.
> What color is it?
> It's green.

Truly, nothing said in the above interaction forbids the interpretation that *the dog is green and lost*. The only things that discourage that interpretation are external&mdash;like the universally agreed-upon conventions that govern the English language.

I don't use the word "universal" lightly in this context: it's true that some conventions of English are not universal. However, I defy you to show me an L1 speaker of English whose first interpretation of that interaction is that the participants are discussing a green lost dog.



Thinking outside the box

Some will claim that thinking outside of the linguistic box is equivalent to thinking outside of the gender-roles box.








> _Next, tell me what's always the last thing to mend,_
> _The middle of middle and end of the end?_

Sure, one answer is the letter "d", but another correct answer is "empty space". After the word "mend" is written, there follows empty space. Between the two "d"s in "middle", there is empty space. There's empty space in the [counter](https://en.wikipedia.org/wiki/Counter_(typography)) of the "d" in "end".


2+2=5



It is a mediocre AI that merely gets the reference to the original 1970s riddle. A truly intelligent AI would recognize and comment upon the fact that the questioner has reversed the roles, probably to trip it up.
